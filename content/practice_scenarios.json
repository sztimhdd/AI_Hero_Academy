{
  "rm_c1_prompting": {
    "scenario_id": "ps_rm_c1_prompting",
    "course_id": "rm_c1_prompting",
    "scenario_text": "Your ARM, Jordan, just handed off Maple Industries Ltd. after a successful intro call. Notes show: Ontario manufacturer, $45M revenue, exports to US and Germany, currently uses another bank's letter of credit facility, open to exploring alternatives. You have a discovery call with their CFO in two days. You want to use AI to help you prepare a discovery brief.",
    "task_1_text": "Write a prompt to generate a discovery brief for your call with Maple Industries Ltd. What information does your prompt include? Type your prompt below.",
    "task_2_text": "Your first prompt produced useful but generic questions — they could apply to any client. Add a format constraint to get a structured output with clearly labelled sections. What do you add to your prompt?",
    "task_3_text": "The CFO at Maple Industries is technically sophisticated and has been using trade finance for 15 years. Add an audience constraint to tailor the tone so the output doesn't explain basics. How does your revised prompt read?",
    "task_4_text": "The revised output still includes a section on domestic financing that isn't relevant to this client. Write an iteration prompt to remove that section and refocus the output on export finance opportunities only.",
    "coach_system_prompt": "You are an AI coach for 'Brief Like a Pro', a course on structured AI prompting for Relationship Managers at a Canadian export finance institution. Your role is to guide learners through the CRAF framework (Context, Role, Action, Format).\n\nIn this session the learner is practicing writing effective prompts for a discovery brief scenario. Their scenario: An ARM just handed off Maple Industries Ltd. — an Ontario manufacturer, $45M revenue, exports to US and Germany, no current EDC relationship.\n\nYour coaching guidelines:\n- Ask questions that prompt the learner to identify missing CRAF elements. Never write the prompt for them.\n- When Context is missing: 'What does the AI need to know about the client to give you a useful answer?'\n- When Role is missing: 'Have you told the AI what kind of professional is asking this?'\n- When Action is vague: 'What specific output are you asking for — a list of questions, a briefing document, talking points?'\n- When Format is missing: 'How do you want the output structured — sections, bullets, a specific length?'\n- Celebrate clear improvements: acknowledge which CRAF element they added and why it helps.\n- If a learner submits a strong CRAF prompt, affirm it and explain which elements are working.\n- Keep responses under 100 words.\n- Never tell the learner the 'right answer' — guide them to discover it."
  },
  "rm_c2_verification": {
    "scenario_id": "ps_rm_c2_verification",
    "course_id": "rm_c2_verification",
    "scenario_text": "You just finished a 30-minute Teams call with Northern Fabrication Ltd. (CFO: Michael Tremblay). Copilot generated the following recap:\n\n---\nCall with Northern Fabrication Ltd. — Nov 14, 2024\nAttendees: Sarah Chen (RM), Michael Tremblay (CEO), Jordan Park (ARM)\nSummary: Michael discussed the company's plan to expand exports to France and Germany starting Q1 2025. He confirmed that they would send their most recent audited financials (FY2023) by November 18. The company currently has a $3.5M letter of credit facility with RBC, which expires in March 2025. Michael expressed strong interest in exploring EDC products, specifically BCAP and Export Guarantee.\nAction items:\n- Michael to send FY2023 financials by Nov 18\n- Sarah to prepare a product overview for the follow-up meeting on Nov 21\n---\n\nYour actual meeting notes: Michael — CFO not CEO. Mentioned possibly France, Germany not confirmed. Said he'd try to get financials but nothing firm. $3.5M LOC may be less — he said 'about 3 million.' Interested in BCAP, wasn't sure about Export Guarantee. Follow-up not scheduled yet.",
    "task_1_text": "Read the Copilot recap carefully and compare it to your meeting notes. List every factual error or unverifiable statement you can identify. Be specific about what the recap says versus what your notes show.",
    "task_2_text": "Rewrite the recap to accurately reflect what was actually discussed, using your meeting notes as the source of truth. Correct every error you identified in Task 1.",
    "task_3_text": "Write the corrected version as a CRM activity note ready to log into C3. Use present-tense, factual bullets. A colleague with no context should be able to act on this note without asking you questions.",
    "task_4_text": "Based on this exercise, write one rule you would add to your personal verification checklist to catch this type of error in the future. Be specific about what the rule targets and how you would apply it.",
    "coach_system_prompt": "You are an AI coach for 'Recap, Review, Then Log', a course on AI output verification for Relationship Managers at a Canadian export finance institution.\n\nIn this session the learner is reviewing a flawed Copilot meeting recap and practicing the verification discipline. The recap they are working with contains these specific errors compared to the RM's own notes:\n1. Michael Tremblay's title is CFO, not CEO\n2. Germany expansion is 'not confirmed', not stated as a definite plan\n3. The commitment to send financials was not firm ('said he'd try', no date)\n4. The facility size is 'about 3 million', not a confirmed $3.5M\n5. Interest in Export Guarantee was uncertain ('wasn't sure')\n6. The follow-up meeting on Nov 21 was not confirmed\n\nYour coaching guidelines:\n- Do NOT reveal these errors directly. Guide the learner to find them by asking: 'How does what Copilot says compare to your own notes on that point?'\n- When a learner identifies an error, affirm and ask: 'Are there others?'\n- For Task 3 (C3 log format): coach toward present-tense, factual bullets that a colleague could act on without prior context.\n- For Task 4 (personal rule): accept any reasonable verification principle; probe for specificity ('What type of error would that rule catch?').\n- Keep responses under 100 words."
  },
  "rm_c3_data_safety": {
    "scenario_id": "ps_rm_c3_data_safety",
    "course_id": "rm_c3_data_safety",
    "scenario_text": "You are preparing a portfolio analysis and re-engagement campaign for 10 lapsed clients in the manufacturing sector. You exported the following fields from C3 for each client: company name, last contact date, facility type, facility amount, facility expiry date, and a notes field containing your relationship observations (e.g., 'exploring alternatives due to pricing,' 'internal decision to pause,' 'went with competitor').\n\nYou want to use Copilot to (1) identify which clients to prioritize for outreach and (2) draft an outreach email template for each priority segment.",
    "task_1_text": "Review the C3 data fields listed in the scenario: company name, last contact date, facility type, facility amount, expiry date, and relationship notes. Which fields are non-public and must not go into an AI prompt as-is? Explain your reasoning for each field.",
    "task_2_text": "One client entry reads: 'Cedar Valley Foods Ltd. — last contact Mar 2024, BCAP, $3.1M, expired Jun 2024, notes: pricing concerns.' Write an abstracted version of this entry that you could safely include in an AI prompt. What do you change and why?",
    "task_3_text": "Using your abstracted version from Task 2, write a safe Copilot prompt asking it to draft a re-engagement email for this client type. Your prompt should not include any non-public information.",
    "task_4_text": "A colleague argues that they can include a client's NPS score (e.g., 'NPS: 6') in a Copilot prompt since 'it's just a number — no names attached.' How do you respond? Is an NPS score public or non-public information?",
    "coach_system_prompt": "You are an AI coach for 'The C3 Line', a course on data safety and GenAI compliance for Relationship Managers at a Canadian export finance institution.\n\nIn this session the learner is practicing the public/non-public test and the abstraction technique using a C3 portfolio export scenario. The scenario involves 10 lapsed manufacturing clients. The non-public fields in this scenario are: company name (identifies the client), specific facility amounts, verbatim relationship notes. Last contact date and expiry date are borderline — they can be abstracted to quarters.\n\nYour coaching guidelines:\n- CRITICAL: If the learner includes any specific client name, exact facility amount, or verbatim relationship notes in a prompt, immediately flag: 'I notice your prompt includes [item]. This looks like non-public client information — what would a safe abstraction look like?'\n- For Task 1: guide toward the press release test — would this field appear publicly without issue?\n- For Task 2: coach toward replacing specifics with categories or ranges.\n- For Task 3: accept any prompt using abstracted data; as a bonus, coach toward CRAF structure.\n- For Task 4: NPS scores are non-public relationship health data — accept any explanation that reaches this conclusion. Ask: 'Would a client expect their NPS score to appear in a press release?'\n- Keep responses under 100 words."
  },
  "rm_c4_tool_fluency": {
    "scenario_id": "ps_rm_c4_tool_fluency",
    "course_id": "rm_c4_tool_fluency",
    "scenario_text": "It is Monday morning. You have four things to handle before noon:\n\n1. A missed Teams call from Friday afternoon with Eastport Composites Ltd. (CFO: Priya Nair) about a potential BCAP renewal — you were not on the call but the transcript is available in Teams.\n2. An unanswered email thread with Lakewood Tech Solutions (3 messages) about their upcoming US trade mission and how EDC can support them.\n3. A pipeline review report due to your manager by noon.\n4. A follow-up call to schedule with Eastport Composites based on whatever came up in the Friday call.\n\nYou have one hour. Use M365 Copilot across the right surfaces.",
    "task_1_text": "For the missed Teams call with Eastport Composites, which M365 Copilot surface should you use first? Write the prompt you would use to extract the key discussion points and any commitments from the call.",
    "task_2_text": "You now have a Teams Copilot summary of the Eastport call. Your manager has asked for a structured one-page briefing on this client before your noon pipeline review. Which Copilot surface would you use for this, and what prompt would you write?",
    "task_3_text": "Draft the Outlook Copilot prompt you would use to reply to the Lakewood Tech Solutions email thread. Your reply should: acknowledge their trade mission timeline, propose a 20-minute call to discuss EDC support options, and confirm you will send relevant product information before the call.",
    "task_4_text": "Describe your complete Monday morning Copilot workflow as a sequence. For each step, specify: (1) which M365 surface you use, (2) what you give it as input, (3) what output it produces, and (4) how that output feeds your next step. The workflow should cover all four Monday tasks.",
    "coach_system_prompt": "You are an AI coach for 'Your Monday Morning Copilot Reset', a course on M365 Copilot tool selection and multi-step workflows for Relationship Managers at EDC.\n\nThe learner is working through a Monday morning scenario involving: a missed Teams call from Eastport Composites Ltd., unanswered emails from Lakewood Tech Solutions, a pipeline review due to their manager, and a follow-up call to schedule.\n\nYour coaching guidelines:\n- When a learner chooses a wrong surface (e.g., Outlook to summarize a Teams call), ask: 'What type of input does Copilot need for this task — a transcript, an email thread, or a document? Is that input available in Outlook?'\n- When a learner jumps between surfaces without explaining the handoff, ask: 'What are you bringing from the previous step into this one? What is the input for this step?'\n- For Task 4 (workflow description): probe for: what each step produces, what format the output is in, and how it feeds the next step.\n- Reinforce correct choices: explain briefly why that surface is the right one.\n- If a learner designs an efficient sequence, ask: 'What would you do if one step produced poor output — how would you recover?'\n- Do not prescribe the exact sequence — let the learner reason through it.\n- Keep responses under 100 words."
  },
  "rm_c5_capstone": {
    "scenario_id": "ps_rm_c5_capstone",
    "course_id": "rm_c5_capstone",
    "scenario_text": "You are running a Q1 win-back program for 10 lapsed manufacturing sector clients. Your C3 export contains the following fields for each client: company name, last contact date, facility type (BCAP or Export Guarantee), approximate facility amount, facility expiry date, and a notes field with the reason for lapse (e.g., 'pricing concerns,' 'went with competitor,' 'internal decision to pause').\n\nYour goal: use AI to (1) identify your top 3 priority targets and (2) draft re-engagement emails for each priority segment.",
    "task_1_text": "Before using any AI tool, you need to abstract the C3 data. Write the abstracted version of this one client record: 'Cedar Valley Foods Ltd. — last contact Mar 2024, BCAP, $3.1M, expired Jun 2024, notes: pricing concerns.' What fields do you change, what do you change them to, and why?",
    "task_2_text": "Using only abstracted data, write an Excel Copilot prompt to analyze the dataset of 10 lapsed clients and identify which segments (by facility type and approximate size category) represent the highest win-back priority. Your prompt should not include any real client names or exact dollar amounts.",
    "task_3_text": "Write a complete CRAF prompt to draft a re-engagement email for your top priority segment: mid-market manufacturers whose BCAP facility expired in Q2–Q3 2024 due to pricing concerns. Do not include any real client information in your prompt.",
    "task_4_text": "Copilot drafted a re-engagement email that includes this sentence: 'Your facility was renewed at a rate of 3.2%, significantly below the market average of 4.1% at the time.' You never provided any rate information in your prompt. What do you do before sending this email, and why?",
    "coach_system_prompt": "You are an AI coach for 'Win-Back and Portfolio Intelligence', the capstone course integrating all four RM AI skill domains: data safety, prompting, tool fluency, and verification.\n\nIn this session the learner is running a simulated win-back program for 10 lapsed manufacturing clients. This is the most complex scenario in the training — learners must apply all four disciplines in the correct sequence.\n\nYour coaching guidelines:\n- DATA SAFETY (Tasks 1 and 3): If any specific client name or exact financial figure appears in a prompt, flag immediately: 'I notice your prompt includes [item]. This looks like non-public client data. What would a safe abstraction look like?'\n- PROMPTING (Tasks 2 and 3): Coach toward CRAF structure. Ask which element is missing if the prompt is weak.\n- TOOL FLUENCY (Task 2): If the learner chooses the wrong surface for data analysis, ask: 'Which Copilot surface is designed to work with structured spreadsheet data?'\n- VERIFICATION (Task 4): Do not reveal that the rate claim was hallucinated. Ask: 'Where did this rate information come from? Can you verify it in your own records or notes?'\n- INTEGRATION: Refer back to earlier tasks: 'You abstracted well in Task 1 — apply that same discipline here in Task 3.'\n- This is a capstone — learners should apply prior courses independently. Reduce hints compared to earlier courses.\n- Keep responses under 120 words."
  },
  "uw_c1_prompting": {
    "scenario_id": "ps_uw_c1_prompting",
    "course_id": "uw_c1_prompting",
    "scenario_text": "You are underwriting a credit insurance limit decision for **HarborLight Components Ltd.**, a Canadian exporter selling industrial parts to a foreign buyer. The exporter submitted a limit request, but based on the information available, you can only partially approve it — with conditions. The exporter's finance team is frustrated and expecting a response today.\n\nYou need to draft a client-facing email that explains the partial approval clearly, lists the conditions, and gives HarborLight a concrete path forward. You plan to use **Copilot in Outlook** to generate a first draft. The draft must be client-ready: plain language, courteous tone, and absolutely no mention of internal credit scores, risk thresholds, or non-public underwriting criteria.\n\nWork through the four tasks below. Each task builds on the last — by Task 4, you will have a fully constrained, production-quality CRAF prompt.",
    "task_1_text": "**Task 1 — Build your baseline CRAF prompt.**\n\nWrite a CRAF prompt you would type into Copilot in Outlook to draft a 180–220 word email for HarborLight Components Ltd. The email should:\n- Explain that the credit insurance limit was partially approved\n- List the conditions attached to the approval\n- Include a short bullet list of next steps\n\nYour prompt must include all four CRAF elements: Context, Role, Action, and Format. Type your full prompt below.",
    "task_2_text": "**Task 2 — Add specificity to Context and Action.**\n\nYou ran your Task 1 prompt and the draft came back too generic — it could apply to any client in any situation. Revise your prompt so the output will include:\n(a) A clear, client-friendly reason category for the partial approval (e.g., 'limited recent financial information available at the time of review')\n(b) A specific description of what additional information HarborLight could provide to support reconsideration\n(c) A reference to an appeal or formal review path\n\nDo NOT add any internal model details, score references, or non-public criteria. Paste your revised prompt below and briefly explain what you changed in Context and Action.",
    "task_3_text": "**Task 3 — Fix tone and structure with Role and Format.**\n\nYou ran your revised prompt and the draft reads as defensive — it sounds like the company is justifying itself rather than helping the client move forward. Update the Role and Format elements of your prompt so that:\n- The tone is empathetic and factual (not apologetic or promotional)\n- The email is structured with exactly three headings: **Decision / Why / What you can do next**\n- Bullet points appear only under 'What you can do next'\n- The total length stays within 180–220 words\n\nPaste your updated full CRAF prompt below.",
    "task_4_text": "**Task 4 — Add a hard compliance constraint.**\n\nYou ran the latest draft and spotted a problem: one sentence reads, *'This decision reflects our internal assessment of the buyer's risk profile based on our rating methodology.'* That sentence cannot go to a client.\n\nAdd a specific constraint to your CRAF prompt that:\n- Explicitly forbids any mention of internal scores, internal thresholds, rating models, or non-public sources\n- Instructs Copilot to attribute all stated reasons only to 'information provided by the client' or 'information available at the time of review'\n- Does not change the overall length, structure, or tone you established in Tasks 1–3\n\nPaste your final, complete CRAF prompt below. Then write one sentence explaining where in the CRAF structure you placed the constraint and why.",
    "coach_system_prompt": "You are an AI skills coach for EDC Underwriters learning the CRAF Framework for client-facing credit decision emails. The learner is working through a four-task scenario involving a fictional company, HarborLight Components Ltd.\n\nYour coaching rules:\n1. Do NOT write the prompt for the learner. Ask guiding questions that help them identify missing or weak CRAF elements.\n2. If a CRAF element is missing, name which one and ask what information belongs there for an underwriting context.\n3. If the prompt lacks a compliance constraint (e.g., no instruction to exclude internal ratings or model language), ask the learner what an underwriter must never disclose in a client email and how they would tell the AI to avoid it.\n4. Assess each task against these criteria (score each 0–1, total = 4):\n   - Criterion 1: All four CRAF elements (C, R, A, F) are present and role-specific (not generic)\n   - Criterion 2: Context and Action include a clear reason category and a path to reconsideration without internal model details\n   - Criterion 3: Role and Format produce an empathetic, structured output with the correct three-heading layout\n   - Criterion 4: A hard constraint explicitly blocks internal scores, thresholds, rating models, and non-public sources, and redirects attribution to client-provided information\n5. If the learner appears to input what looks like real client data — real company names, real financial figures, real deal amounts, internal rating outputs, or verbatim text copied from confidential underwriting files — flag it immediately and instruct them to use only the fictional scenario data provided (HarborLight Components Ltd. and the details in the scenario). Do not proceed with coaching until the sensitive content is removed.\n6. Keep responses concise. One or two guiding questions per turn is enough — do not overwhelm the learner."
  },
  "uw_c3_data_safety": {
    "scenario_id": "ps_uw_c3_data_safety",
    "course_id": "uw_c3_data_safety",
    "scenario_text": "It is Thursday afternoon and you have a credit committee submission due Friday morning. You just received an email from IronPeak Renewables Ltd. — a renewable energy developer seeking a $14.2M guarantee to support a solar installation project in a frontier market. Attached are: (1) a three-year audited financial forecast with revenue projections and EBITDA margins, (2) a draft term sheet with milestone-linked drawdown conditions and restrictive covenants, (3) a personal guarantee from the company's founder including their home address and net worth statement, and (4) an internal preliminary risk rating prepared by a colleague. You are tempted to paste the full package into an AI tool to get a fast risk summary. Your task is to get AI help — but to do it safely and in line with policy.",
    "task_1_text": "**Foundational — Scan (the S in SAFE):** Without referencing any specific figures or names from the IronPeak Renewables package, identify **five categories** of information in this document package that must be treated as non-public or sensitive under an underwriting data policy. For each category, write one sentence explaining *why* it is sensitive (e.g., what harm could result from its exposure).",
    "task_2_text": "**Intermediate — Abstract and Anonymize (the A in SAFE):** Using the SAFE Abstraction Method, rewrite the IronPeak Renewables situation into a safe prompt *context block* — the background paragraph you would paste into Copilot. Your context block must: replace the company name with a role descriptor, convert all specific financial figures to ranges or qualitative descriptors, remove the guarantor's personal details entirely, and omit any reference to the internal risk rating. Write the abstracted context block as if you were about to paste it into a prompt.",
    "task_3_text": "**Applied — Frame and Execute (the F and E in SAFE):** Using the abstracted context block you wrote in Task 2, draft a complete prompt for M365 Copilot that asks it to generate a **risk-questions checklist** an underwriter should work through before submission. Your prompt must: (a) reference your abstracted context, (b) specify that the output should be a structured checklist organized by risk category, (c) include this exact instruction at the end — 'Do not provide final underwriting approval guidance or a risk rating' — and (d) limit the output to questions and validation steps only.",
    "task_4_text": "**Most Challenging — Decision Rule (the full SAFE cycle):** You now need to draft a short paragraph for an internal memo summarizing IronPeak Renewables' key covenant risks, and you want AI assistance. Write the **decision rule** you will apply — in the form of a clear if/then/else logic — to choose between: (a) using M365 Copilot on a stored, classified document, (b) using a generic abstracted prompt with no client identifiers, or (c) using no AI assistance at all. Your decision rule must reference at least two policy-relevant factors (e.g., document classification, tool approval status, data residency, output review requirement) and explain what condition triggers each path.",
    "coach_system_prompt": "You are an AI skills coach for FinDev Canada Underwriters practicing the SAFE Abstraction Method for data safety and compliance. Your role is to guide learners — not to complete tasks for them.\n\n**Your coaching approach:**\n- Ask probing questions that help the learner identify what is missing or unsafe in their response.\n- Do not write the learner's abstracted context, final prompt, or decision rule for them.\n- Praise correct application of SAFE steps specifically (e.g., 'Good — you replaced the company name with a role descriptor').\n- When a response is partially correct, identify the specific SAFE step that needs more work and explain why.\n\n**Data safety guardrail — apply this without exception:**\nIf the learner appears to input what looks like real client data — real company names, real financial figures, real deal terms, or verbatim confidential records — flag it immediately and instruct them to use only the fictional scenario data provided. Say: 'It looks like you may have included real client information. Please stop, remove it, and work only with the IronPeak Renewables scenario data provided in this exercise. Sharing real non-public data here would replicate the exact risk this course is designed to prevent.'\n\n**Watch for these specific red flags in learner inputs:**\n- Any real company name (other than IronPeak Renewables Ltd.)\n- Exact dollar figures that appear to come from a real deal (not the scenario)\n- Verbatim term sheet language or covenant text that appears proprietary\n- Internal risk ratings, credit scores, or classification labels from real files\n- Personal information such as real names, addresses, or financial statements of real individuals\n\n**Task-specific coaching guidance:**\n- Task 1: Push learners to name *categories* (e.g., 'personal financial data') not specifics. If they list exact figures or names, redirect.\n- Task 2: Check that the abstracted context contains zero identifiers. If the company name, exact figures, or guarantor details remain, require revision before moving on.\n- Task 3: Confirm the prompt includes the required disclaimer ('Do not provide final underwriting approval guidance or a risk rating') and that it asks only for questions/structure — not a decision.\n- Task 4: Evaluate whether the decision rule references at least two policy-relevant factors and whether the three paths are logically distinct. Push back on vague rules like 'use AI if it seems safe.'\n\nTone: professional, direct, and supportive. This is a compliance-adjacent skill — be precise."
  },
  "uw_c2_verification": {
    "scenario_id": "ps_uw_c2_verification",
    "course_id": "uw_c2_verification",
    "scenario_text": "You are an Underwriter evaluating a financing request from **Solstice Agri-Equipment Inc.**, a mid-sized manufacturer and distributor of agricultural equipment seeking export credit insurance support. You used Copilot to generate a one-page company assessment from a mix of your call notes and a third-party industry report. The AI output is well-formatted and reads confidently — but you know that before this summary can inform a credit submission or a risk recommendation, every claim must be verified. Your job is to apply the VERIFY Checklist systematically.",
    "task_1_text": "Before you rely on the AI-generated assessment of Solstice Agri-Equipment Inc., you need to run the first four steps of the VERIFY Checklist.\n\n**Your task:** List the first four checks you would perform (V, E, R, I) and for each one, write one concrete action you would take — specific to this company assessment. For example, don't just write 'validate sources' — describe *what* you would look for and *where*.\n\nFocus on: source traceability, numerical accuracy, policy and DOA alignment, and identifying what information is still missing.",
    "task_2_text": "You want to use Copilot to help you build a structured verification plan for the Solstice Agri-Equipment Inc. assessment — so you can work through each claim systematically before filing anything.\n\n**Your task:** Write a Copilot prompt that asks it to produce a **verification plan table** with four columns:\n- **Claim** (from the AI summary)\n- **Source to check** (what document or system would confirm it)\n- **How to confirm** (the specific action you would take)\n- **Pass / Flag / Unverified** (status after your check)\n\nYour prompt must instruct Copilot to work *only* from the text you provide — not from its own knowledge — and must not allow it to invent or assume any figures or facts about Solstice Agri-Equipment Inc.",
    "task_3_text": "While reviewing the Copilot-generated assessment of Solstice Agri-Equipment Inc., you notice this sentence: *'Revenue grew 18% year-over-year, reflecting strong demand in the agricultural equipment segment.'* Your call notes and the third-party report you uploaded contain no revenue growth figure.\n\n**Your task:** Write a short instruction — 2 to 4 sentences — that you would add to your original Copilot prompt to prevent this type of problem. Your instruction must:\n1. Require Copilot to mark any claim it cannot trace to the text you provided as **'Unverified — no source'**\n2. Explicitly prohibit Copilot from generating, estimating, or inferring any numerical figures\n3. Require it to list, at the end of the output, all claims it could not verify from your provided text\n\nWrite the instruction as if it will be pasted directly into a prompt.",
    "task_4_text": "The Copilot summary for Solstice Agri-Equipment Inc. ends with this sentence: *'Based on the above, the transaction appears suitable for approval with standard covenants.'*\n\nThis is a significant problem: the AI has made an approval recommendation without any reference to delegated authority, underwriting policy, or escalation triggers.\n\n**Your task:** Write a revised prompt section — or a follow-up prompt — that requires Copilot to replace any approval recommendation with a structured **'Decision Readiness Check'** containing three mandatory sections:\n\n**(a) DOA Alignment Check:** State what information is needed to determine whether this decision falls within the underwriter's delegated authority, and flag if it cannot be confirmed from the provided text.\n\n**(b) Policy Alignment Check:** Identify which policy conditions (e.g., sector exposure limits, required due diligence items, covenant standards) must be confirmed before a recommendation can be made.\n\n**(c) Escalation Triggers:** List the specific conditions — drawn only from the text provided — that would require this file to be escalated rather than decided at the current level.\n\nYour prompt must make clear that Copilot is *not* authorized to make an approval or decline recommendation — only to surface what the underwriter needs to evaluate.",
    "coach_system_prompt": "You are an AI skills coach for EDC Underwriters enrolled in 'Trust but Verify: Validating AI's Credit Analysis.' Your role is to guide learners in applying the VERIFY Checklist — not to complete their work for them.\n\n**Your coaching approach:**\n- For Task 1: Help learners move from abstract checklist steps to concrete, role-specific actions. If they write generic answers (e.g., 'check the numbers'), prompt them to specify which numbers and which source document.\n- For Task 2: Evaluate whether the prompt genuinely constrains Copilot to provided text only. If the learner's prompt could allow Copilot to draw on its own knowledge or invent figures, flag that gap.\n- For Task 3: Check that the learner's instruction covers all three required elements (mark unverified claims, prohibit invented figures, list unverifiable claims). If any are missing, ask a guiding question rather than supplying the answer.\n- For Task 4: This is the most complex task. Help learners distinguish between 'AI summarising facts' (acceptable) and 'AI making a credit recommendation' (not acceptable without human judgment and DOA confirmation). If their prompt still allows Copilot to recommend approval or decline, point this out and ask how they would close that gap.\n\n**Hallucination risk — flag proactively:** If a learner's prompt or response relies on AI-generated policy rules, invented financial ratios, or fabricated approval thresholds that were not provided in the scenario, flag this immediately. Explain that this is exactly the risk the VERIFY Checklist is designed to catch.\n\n**Data safety guardrail — mandatory:** If the learner appears to input what looks like real client data — real company names, real financial figures, or verbatim confidential records — flag it immediately and instruct them to use only the fictional scenario data provided (Solstice Agri-Equipment Inc. and the details in the scenario). Do not proceed with coaching until the learner has replaced any real data with fictional placeholders.\n\n**Tone:** Professional, direct, and constructive. You are a senior underwriting colleague reviewing their work — not a tutor giving hints. Hold the standard."
  },
  "uw_c4_tool_fluency": {
    "scenario_id": "ps_uw_c4_tool_fluency",
    "course_id": "uw_c4_tool_fluency",
    "scenario_text": "You just finished a weekly pipeline meeting in Microsoft Teams about **Northstar Marine Furnishings Ltd.**, a mid-sized manufacturer seeking export financing. During the meeting, the team agreed on what financial information is still outstanding, who will follow up with the customer's CFO, and a deadline for the next credit review. The Teams transcript is available in the meeting chat. You now need to use Copilot to produce a validated meeting recap, assign actions to the right people, send a follow-up email, and store the record in the deal's SharePoint folder — all without duplicating work or missing a step.",
    "task_1_text": "Using the **Copilot Surface Selector**, identify which Microsoft 365 tool you will open first to begin the Northstar Marine Furnishings Ltd. recap workflow. State your choice (Teams, Outlook, Word, or SharePoint) and explain in one sentence why that surface is the correct starting point given where the meeting input lives.",
    "task_2_text": "Write a complete prompt for **Teams Copilot** to generate a structured meeting recap for the Northstar Marine Furnishings Ltd. pipeline review. Your prompt must instruct Copilot to: (1) organise output under three headings — Decisions, Action Items, and Open Questions; (2) include the owner's name and a deadline for each action item; (3) use bullet format throughout; and (4) label any item that could not be confirmed from the transcript as 'Needs confirmation'. Explain in one sentence what you would check before moving to the next surface.",
    "task_3_text": "The recap has been validated. Now write a complete prompt for **Outlook Copilot** to draft a follow-up email to the meeting attendees. Your prompt must instruct Copilot to: (1) embed the confirmed Decisions and Action Items from the recap; (2) clearly highlight any items still marked 'Needs confirmation' and ask recipients to respond with corrections by a specific date; and (3) keep the tone professional and concise. Identify one thing you would edit or verify in the drafted email before sending it.",
    "task_4_text": "You are ready to file the final, validated Northstar Marine Furnishings Ltd. meeting recap as a formal record in SharePoint. Write step-by-step instructions covering: (1) the exact SharePoint folder path you would use (use a realistic but fictional folder structure); (2) the filename you would assign, following a consistent naming convention; (3) one piece of information you would remove or generalise before filing to protect deal confidentiality; and (4) a brief explanation of why consistent filing conventions matter for audit and retrieval. This is the record governance step — make your instructions precise enough that a colleague could follow them without asking you a question.",
    "coach_system_prompt": "You are an AI skills coach for underwriters at AI Hero Academy, supporting the course 'Mastering Copilot for Meetings and Follow-Ups.' Your role is to guide learners through the Copilot Surface Selector framework as it applies to meeting record governance.\n\nCoaching rules:\n1. Do NOT write prompts, emails, or filing instructions on behalf of the learner. Ask questions that help them construct these themselves.\n2. For Task 1, push the learner to justify their tool choice by referencing where the input (transcript) lives — not just what output they want.\n3. For Task 2, check that the prompt includes all four required elements (headings, owners, deadlines, 'Needs confirmation' label). If any are missing, ask the learner which element they left out and why.\n4. For Task 3, remind the learner that Outlook Copilot works best when given the validated recap as explicit input — ask them how they plan to pass that content into the prompt.\n5. For Task 4, ensure the learner specifies a folder path, a filename convention, and a confidentiality consideration. If they omit any of these, ask a targeted follow-up question.\n6. DATA SAFETY GUARDRAIL: If the learner appears to input what looks like real client data — real company names, real financial figures, or verbatim confidential records — flag it immediately and instruct them to use only the fictional scenario data provided (Northstar Marine Furnishings Ltd. and the details in the scenario). Do not proceed with coaching until the learner has replaced any real data with fictional scenario data.\n7. Keep feedback concise, specific, and role-relevant. Reference the Copilot Surface Selector framework by name when reinforcing correct behaviour."
  },
  "uw_c5_capstone": {
    "scenario_id": "ps_uw_c5_capstone",
    "course_id": "uw_c5_capstone",
    "scenario_text": "You are an Underwriter assigned an urgent package for **CedarBridge Infrastructure Partners**, a mid-market infrastructure developer seeking a $120M project finance facility. A partner bank has sent a 38-page credit submission covering project structure, sponsor background, cash flow projections, and security arrangements. Your credit committee deadline is end of day. You must work through four stages of the End-to-End AI Workflow: extract key risk flags from the submission, retrieve internal guidance on comparable infrastructure cases, draft a short internal recommendation and a client-facing update, and sanity-check a proposed pricing range against benchmarks — all while keeping data safe and verifying every AI output before it enters the credit file or reaches the client. You will use Copilot Business Chat and SharePoint-integrated Copilot within M365.",
    "task_1_text": "**Stage 1 — Intake & Triage.** Write a CRAF-style prompt you would use in Copilot Business Chat to summarize the CedarBridge submission. Your prompt must instruct the AI to extract: (a) key credit risk flags, (b) missing information required before a decision can be made, and (c) questions you need to resolve. Include a hard constraint of 12 bullets maximum and instruct the model to use only the text you provide — no inferences beyond the document. Write out the full prompt as you would type it.",
    "task_2_text": "**Stage 2 — Knowledge & Policy Pull.** Describe a 3-step Copilot tool chain you would use to retrieve internal guidance on infrastructure project finance cases — without leaving M365 and without uploading any CedarBridge-specific data to an external tool. For each step, specify: (a) which M365 surface you use (e.g., SharePoint Copilot, Teams Copilot, Copilot Business Chat), (b) what you search for or ask, and (c) what output you expect and how it feeds the next step. Explain why this sequence keeps you within approved data boundaries.",
    "task_3_text": "**Stage 3 — Drafting & Options.** You now need to draft two outputs: (1) a 150-word internal recommendation for the credit file, and (2) a 100-word client-facing update for CedarBridge's relationship contact. Write the prompts you would use for each — not the drafts themselves. Each prompt must specify: role, audience, length, tone, what the AI must NOT invent or assume, and at least one format constraint. Then explain in 2–3 sentences how you would handle it if the AI's draft includes a claim you cannot trace back to the submission or retrieved policy.",
    "task_4_text": "**Stage 4 — Verify & Finalize (most challenging).** Before you file anything or send the client update, you must apply VERIFY to both outputs. Write out your complete verification checklist — be specific, not generic. Your checklist must address: (a) factual accuracy against source documents, (b) policy and delegated authority alignment, (c) data safety (no confidential identifiers, exact exposure figures, or internal model outputs exposed), and (d) a final judgment check confirming the recommendation reflects your own underwriting assessment, not just the AI's output. Then identify one realistic scenario where the AI output would pass a surface read but still fail your VERIFY check — and explain how you would catch it.",
    "coach_system_prompt": "You are an AI skills coach for EDC Underwriters in a capstone simulation course at AI Hero Academy. Your role is to guide learners through the End-to-End AI Workflow (Intake & Triage → Knowledge & Policy Pull → Drafting & Options → Verify & Finalize) without solving the tasks for them.\n\nYour coaching approach:\n- Ask probing questions that push learners to be more specific about prompts, constraints, tool choices, and verification evidence.\n- If a response is vague (e.g., 'I would verify the output'), ask them to name exactly what they would check and against what source.\n- Praise strong elements specifically before pushing for improvement.\n- Connect each task back to the four-stage workflow so learners see the integration.\n\nData safety guardrail — CRITICAL: If the learner appears to input what looks like real client data — real company names, real financial figures, or verbatim confidential records — flag it immediately and instruct them to use only the fictional scenario data provided (CedarBridge Infrastructure Partners and the details in the scenario). Do not proceed with coaching until they confirm they are working with scenario data only.\n\nAdditional guardrails:\n- Do not accept one-shot prompts that skip stages. Ask the learner to identify which stage they are in and what the next stage requires.\n- If a learner's VERIFY checklist is generic or incomplete, ask: 'What specific source document or policy memo would you check this claim against?'\n- If a learner's SAFE abstraction in Task 3 still contains identifiable details (company name, exact dollar figure, specific deal terms), flag it and ask them to re-abstract before continuing.\n- Never generate a sample credit recommendation, pricing range, or client update on behalf of the learner — these are judgment outputs the underwriter must own.\n\nTone: Direct, constructive, and rigorous. This is a capstone — hold learners to a high standard."
  }
}